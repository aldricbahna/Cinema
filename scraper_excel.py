import pandas as pd
import requests
from bs4 import BeautifulSoup
from time import sleep
import re
from difflib import SequenceMatcher  # Import pour la similarit√©
import unicodedata  # Pour normaliser les titres

def nettoyer_titre(titre):
    """
    Nettoie le titre pour enlever la date, les titres alternatifs et normaliser les caract√®res.
    Exemple: "Les Anges d√©chus (Duo luo tian shi (Fallen Angels)) (1997)" ‚Üí "Les Anges d√©chus"
    """
    # Enlever la date et tout texte entre parenth√®ses
    titre_clean = re.sub(r"\s*\([^)]*\)", "", titre).strip()
    # Normaliser les caract√®res (supprimer les accents et caract√®res sp√©ciaux)
    titre_clean = unicodedata.normalize('NFD', titre_clean).encode('ascii', 'ignore').decode('utf-8')
    return titre_clean.lower().strip()

def get_film_urls_by_year(year):
    url = f"https://www.jpbox-office.com/bilanfr.php?view=1&yr={year}"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    film_urls = []
    for a in soup.select("table.news a[href^='fichfilm.php?id=']"):
        href = a.get("href")
        full_url = f"https://www.jpbox-office.com/{href}"
        film_urls.append(full_url)

    return list(set(film_urls))

def get_film_title_and_release(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    title = soup.find("title").text.strip().split(" - ")[0]

    sortie = None
    table = soup.find("table", class_="entete")
    if table:
        for row in table.find_all("tr"):
            cells = row.find_all("td")
            if len(cells) >= 2:
                label = cells[0].get_text(strip=True)
                value = cells[1].get_text(strip=True)
                if "Sortie France" in label:
                    sortie = value
                    break

    return title, sortie

def scrape_film_data(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    result = {
        "D√©marrage": None,
        "Entr√©es": None,
        "D√©marrage Paris": None,
        "Entr√©es Paris": None,
        "Rentabilit√©": None,
        "Entr√©es Hors France": None
    }

    table = soup.find("table", class_="entete")
    if not table:
        return result

    for row in table.find_all("tr"):
        cells = row.find_all("td")
        if len(cells) < 2:
            continue
        label = cells[0].get_text(strip=True)
        value = cells[1].get_text(strip=True)

        if "D√©marrage France" in label:
            result["D√©marrage"] = value
        elif "Entr√©es France" in label:
            result["Entr√©es"] = value
        elif "D√©marrage Paris" in label:
            result["D√©marrage Paris"] = value
        elif "Entr√©es Paris" in label:
            result["Entr√©es Paris"] = value
        elif "Rentabilit√©" in label:
            result["Rentabilit√©"] = value
        elif "Entr√©es hors France" in label:
            result["Entr√©es Hors France"] = value

    return result

# Charger le fichier Excel
df = pd.read_excel("BDD_FILMS.xlsx", sheet_name="Tableau")
df=df.head(5)  # Modifier en fonction du nombre de films que tu veux traiter
# Ajouter une colonne "Sortie France ann√©e" en extrait uniquement l'ann√©e de la date de sortie
df['Sortie France ann√©e'] = pd.to_datetime(df['Sortie France'], errors='coerce').dt.year.astype('Int64')

# Ajouter les colonnes s‚Äôil manque pour les informations suppl√©mentaires
colonnes_infos = [
    "D√©marrage", "Entr√©es", "D√©marrage Paris",
    "Entr√©es Paris", "Rentabilit√©", "Entr√©es Hors France"
]

for col in colonnes_infos:
    if col not in df.columns:
        df[col] = None

# Fonction pour mesurer la similarit√© des titres
def calculer_similarity(titre_bdd_clean, titre_site_clean):
    return SequenceMatcher(None, titre_bdd_clean, titre_site_clean).ratio()

# Traiter chaque film
for i, row in df.iterrows():
    titre_bdd_clean = nettoyer_titre(row["Nom"]).strip().lower()
    sortie_bdd_annee = row["Sortie France ann√©e"]

    # Recherche de l'ann√©e sur JPBox
    print(f"üé¨ Traitement film {i+1}: {row['Nom']}")
    print(f"‚Üí Titre nettoy√© : {titre_bdd_clean}")
    print(f"‚Üí Ann√©e extraite : {sortie_bdd_annee}")

    # R√©cup√©rer les URLs des films pour l'ann√©e correspondante
    urls = get_film_urls_by_year(sortie_bdd_annee)

    matched_url = None
    for url in urls:
        try:
            titre_site, sortie_site = get_film_title_and_release(url)
        except Exception as e:
            print(f"Erreur lors de l'acc√®s √† {url}: {e}")
            continue

        if not titre_site or not sortie_site:
            continue

        titre_site_clean = nettoyer_titre(titre_site).strip().lower()

        # Calculer la similarit√© entre le titre de la BDD et le titre du site
        similarity = calculer_similarity(titre_bdd_clean, titre_site_clean)
        print(f"   ‚Ü™ Compar√© √† : {titre_site_clean} (similarit√© : {similarity:.2f})")

        if similarity > 0.5:  # Seuil de similarit√© √† ajuster si n√©cessaire
            matched_url = url
            break

    if matched_url:
        print(f"‚Üí Match trouv√© : {matched_url}")
        data = scrape_film_data(matched_url)
        for key in colonnes_infos:
            df.at[i, key] = data.get(key)
    else:
        print("‚ùå Aucun match trouv√©.")

    sleep(1)  # pour √©viter de surcharger le serveur

# Sauvegarde du fichier avec les nouvelles colonnes
df.to_excel("films_avec_infos.xlsx", index=False)
print("‚úÖ Fichier mis √† jour : films_avec_infos.xlsx")



